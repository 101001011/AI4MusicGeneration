## HS-MAD：层级符号对齐的音乐音频扩散模型

**Hierarchical Symbolic-Conditioned Music Audio Diffusion (HS-MAD)**

### 摘要

在音乐音频生成领域，实现高保真度（Fidelity）与精确结构控制（Controllability）的平衡是长期存在的挑战。潜在扩散模型（LDM）虽然在音质上达到了最先进水平，但由于缺乏显式的结构化引导机制，它们在遵循复杂符号指令（如乐谱）时常出现时序漂移和结构失真。本文提出 HS-MAD（Hierarchical Symbolic-Conditioned Music Audio Diffusion），一种新颖的扩散架构，旨在解决这一核心矛盾。HS-MAD 的核心洞察在于利用音乐的层级本质（从宏观曲式到微观音符）与 U-Net 架构的多分辨率特性之间的同构性（Isomorphism）。我们引入了一个基于 Conformer 的分层符号编码器（HSE），用于提取时间精确对齐的多尺度音乐特征。随后，我们设计了多分辨率条件注入（MRCI）机制，将高层结构信息注入 U-Net 的低分辨率层，将底层时序信息注入高分辨率层。我们进一步提出了“跳跃连接调制”（Skip Connection Modulation）以增强时序精度，并引入了“解耦无分类器指导”（Decoupled CFG）策略以实现结构与风格的独立控制。本文提供了详尽的架构设计、算法细节和实验方案，论证了 HS-MAD 在实现高质量、结构连贯的音乐生成方面的潜力。

### 1. 引言：动机与贡献

音乐是一种高度结构化且具有层级特性的信号。生成模型在尝试复现这种复杂性时，必须同时解决声学保真度和音乐结构连贯性的问题。

近年来，潜在扩散模型（LDM）[Rombach et al., 2022] 在音频生成领域取得了突破性进展。AudioLDM [Liu et al., 2023] 和 Stable Audio 等模型能够生成高度逼真的音色和织体。然而，它们的控制机制通常依赖于全局嵌入向量（例如来自文本提示）。这种粗粒度的控制无法精确指定音乐的时间结构、和声进行或复调关系。在执行符号到音频合成任务时，现有 LDM 常采用“单点注入”策略，即将所有信息压缩后注入 U-Net 的瓶颈层。这造成了严重的信息瓶颈，导致时序漂移和细节丢失。

HS-MAD 旨在通过一个关键的理论洞察来解决这一矛盾：**音乐的层级结构与 U-Net 架构的多分辨率特性之间存在天然的同构性。** U-Net [Ronneberger et al., 2015] 的深层（低分辨率）捕捉全局上下文，而浅层（高分辨率）处理局部细节。这与音乐从曲式、和声到具体音符事件的层级组织高度吻合 [Paiement et al., 2009]。

HS-MAD 首次显式地将这两种层级结构进行对齐和映射。我们提出了一种“分而治之”的策略：将高层音乐结构信息引导 U-Net 的深层计算，将底层音乐细节信息引导 U-Net 的浅层计算。

本文的主要贡献与创新点如下：

1. **[核心创新] HS-MAD 框架**：提出了通过显式对齐音乐层级与 U-Net 多分辨率特性来实现精确结构控制的音乐生成框架。
2. **[创新点] 基于 Conformer 的分层符号编码器 (HSE) 与同步机制**：设计了一个层级化的 Conformer 架构，并结合了精确的时序同步预处理，以生成与 U-Net 精确对齐的多尺度表示。
3. **[创新点] 多分辨率条件注入 (MRCI) 与跳跃连接调制 (Skip Connection Modulation)**：开发了层级注入策略，并创新性地引入了对跳跃连接的符号调制，以显著增强微观时序精度和瞬态清晰度。
4. **[创新点] 解耦无分类器指导 (Decoupled CFG)**：提出了一种针对结构和风格条件的多模态 CFG 策略，允许独立控制不同条件的引导强度。

### 2. HS-MAD 架构详解

HS-MAD 基于 LDM 框架，包含一个预训练的音频 VAE（编码器 E，解码器 D），以及核心的去噪网络 ϵ_θ。去噪网络由分层符号编码器 (HSE) 和多分辨率条件注入 U-Net (MRCI U-Net) 组成。

代码段

```
graph TD
    subgraph "HS-MAD 详细架构"
        direction TB

        %% 1. 输入与编码
        Symbolic_Input("符号输入 S (MIDI)") --> HSE("分层符号编码器 (HSE)")
        Style_Input("风格输入 T (文本)") --> Style_Encoder("风格编码器 (CLAP/T5)") --> F_style("F_style")

        subgraph HSE [HSE (Conformer-based)]
            direction TB
            S_in("S") --> SRM("同步渲染模块 (SRM)") --> S_sync("同步表示")
            S_sync --> Conformer_1("Stage 1: Event") --> F_event("F_event (高分辨率, T_H)")
            F_event -- "Strided Conv" --> Conformer_2("Stage 2: Local") --> F_local("F_local (中分辨率, T_M)")
            F_local -- "Strided Conv" --> Conformer_3("Stage 3: Global") --> F_global("F_global (低分辨率, T_L)")
        end

        %% 2. MRCI U-Net (去噪网络 ε_θ)
        Noisy_Latent_zt("带噪潜在表示 z_t") --> MRCI_U_Net

        subgraph "MRCI U-Net"
            direction TB
            Input_zt("z_t") --> U_Down_1("下采样块 1 (T_H)")
            U_Down_1 --> U_Down_2("下采样块 2 (T_M)")
            U_Down_2 --> U_Bottleneck("瓶颈层 (T_L)")

            U_Bottleneck --> U_Up_2("上采样块 2 (T_M)")
            U_Up_2 --> U_Up_1("上采样块 1 (T_H)")
            U_Up_1 --> Output_e("预测噪声 ε_θ")

            %% 跳跃连接调制 (创新点)
            U_Down_1 -- "Z_skip_1" --> Skip_Mod_1("Skip Modulation")
            F_event -- "TCA (Temporal Cross-Attention)" --> Skip_Mod_1
            Skip_Mod_1 -- "Z'_skip_1" --> U_Up_1

            U_Down_2 -- "Z_skip_2" --> Skip_Mod_2("Skip Modulation")
            F_local -- "TCA" --> Skip_Mod_2
            Skip_Mod_2 -- "Z'_skip_2" --> U_Up_2

            %% 多分辨率条件注入 (MRCI)
            F_event -- "TCA" --> U_Down_1 & U_Up_1
            F_local -- "TCA" --> U_Down_2 & U_Up_2
            F_global -- "TCA" --> U_Bottleneck

            %% 风格注入
            F_style -- "FiLM/AdaLN" --> U_Down_1 & U_Down_2 & U_Bottleneck & U_Up_2 & U_Up_1
        end
    end
```

*图 1：HS-MAD 架构概览。HSE 通过 SRM 实现同步，并通过 Conformer 提取多尺度特征。MRCI U-Net 在对应层级注入这些特征，并采用创新的跳跃连接调制机制。*

#### 2.1 分层符号表示定义

我们定义三个层次的音乐特征，其时间分辨率与 U-Net 的层级（高 T_H、中 T_M、低 T_L）精确对齐。

1. **F_event (事件层, T_H)**: 捕捉精确的音符属性（音高、力度、微观时序）。
2. **F_local (局部层, T_M)**: 捕捉局部和声（如和弦标签、Chromagram）和节奏模式。
3. **F_global (全局层, T_L)**: 捕捉曲式结构、全局调性和速度曲线。

#### 2.2 分层符号编码器 (HSE) (创新点)

HSE 的关键挑战在于将异步的符号事件（MIDI）转换为与 U-Net 同步对齐的多尺度表示。我们采用一个两阶段架构：同步渲染模块（SRM）和层级特征提取器（HFE）。

##### 2.2.1 同步渲染模块 (SRM)

SRM 负责将 MIDI 事件 S 转换为一个同步的、高分辨率的输入表示 S_sync∈RT_H×D_in，其时间维度 T_H 与 VAE 潜在空间的基础分辨率对齐。我们将其实现为“软钢琴卷帘”。D_in 包含音高、力度、起始（Onset）和持续时间信息。SRM 使用平滑窗口函数（如高斯核）来表示音符事件，以保留微观时序并确保可微性。

##### 2.2.2 层级特征提取器 (HFE)：基于 Conformer

HFE 从 S_sync 中提取层级特征。我们采用 Conformer [Gulati et al., 2020] 架构，它结合了卷积的局部建模能力和 Transformer 的全局上下文捕捉能力。

HFE 由三个阶段组成，阶段之间通过时间下采样连接。关键是下采样因子必须与 U-Net 的结构精确匹配。我们使用步长卷积（Strided Convolution）进行下采样，因为它比简单的池化能更好地学习如何聚合时序信息。

**算法 1：分层符号编码器 (HSE) 伪代码**

Python

```
class HierarchicalSymbolicEncoder(nn.Module):
    def __init__(self, downsampling_factors):
        super().__init__()
        # downsampling_factors (例如 [R1, R2]) 必须与 U-Net 匹配
        self.R1, self.R2 = downsampling_factors
        self.SRM = SymbolicRenderingModule()

        # HFE Stages (Conformer Blocks)
        self.Stage1_Event = ConformerBlocks(...)
        self.Downsample1 = StridedConv1D(stride=self.R1, ...)
        self.Stage2_Local = ConformerBlocks(...)
        self.Downsample2 = StridedConv1D(stride=self.R2, ...)
        self.Stage3_Global = ConformerBlocks(...)

    def forward(self, S_midi, T_H):
        # 1. 同步渲染模块 (SRM)
        S_sync = self.SRM(S_midi, T_H) # [B, T_H, D_in]

        # 2. 层级特征提取器 (HFE)
        # Stage 1: Event Level
        F_event = self.Stage1_Event(S_sync) # [B, T_H, D_event]

        # Stage 2: Local Level
        H_mid = self.Downsample1(F_event)
        F_local = self.Stage2_Local(H_mid) # [B, T_M, D_local]

        # Stage 3: Global Level
        H_global = self.Downsample2(F_local)
        F_global = self.Stage3_Global(H_global) # [B, T_L, D_global]

        return F_event, F_local, F_global
```

#### 2.3 多分辨率条件注入 U-Net (MRCI U-Net) (核心创新点)

MRCI U-Net 是去噪网络 ϵ_θ。我们通过时序交叉注意力（Temporal Cross-Attention, TCA）将 HSE 的输出注入到 U-Net 的对应层级。

##### 2.3.1 时序交叉注意力 (TCA)

在 U-Net 的第 l 层，给定特征图 Z_l 和对应的符号特征 F_l。由于 HSE 的同步化设计，Z_l 和 F_l 具有相同的时间维度。

$$ \text{TCA}(Z_l, F_l) = \text{Attention}(Q=W_Q Z_l, K=W_K F_l, V=W_V F_l) $$

TCA 允许 U-Net 在每个时间步参考精确对齐的音乐结构信息。

##### 2.3.2 分层注入策略

我们显式地进行层级映射：F_global 注入瓶颈层（引导全局结构）；F_local 注入中间层（约束局部模式）；F_event 注入高分辨率层（确保精确时序）。

##### 2.3.3 跳跃连接调制 (Skip Connection Modulation) (创新点)

U-Net 的跳跃连接负责传递高频细节，对音频瞬态至关重要。我们提出直接使用符号信息调制跳跃连接，以确保高频细节与符号结构精确对齐。

令 Z_skip 为从编码器传递的特征，F_l 为对应的符号特征。我们计算调制后的跳跃连接 Z′_skip：

$$ Z'*{skip} = Z*{skip} + \gamma_l \cdot \text{TCA}(Z_{skip}, F_l) $$

其中 γ_l 是一个可学习的门控参数（初始化为接近零，类似于 ControlNet [Zhang et al., 2023]），用于平滑地引入控制。特别是使用 F_event 调制最高分辨率的跳跃连接，可以极大地增强音符起始时间的精确性和清晰度。

#### 2.4 风格与音色控制

HS-MAD 天然支持结构（由 HSE 控制）与风格/音色（由文本 T 控制）的解耦。文本通过预训练编码器（如 CLAP 或 T5）编码为全局风格向量 F_style。我们采用特征级线性调制（FiLM）[Perez et al., 2018] 或自适应层归一化（AdaLN）将 F_style 注入到 U-Net 的所有层级，与结构信息正交工作。

#### 2.5 训练策略与解耦 CFG

##### 2.5.1 训练目标

训练目标是标准的 LDM 损失函数，条件包含层级化符号特征 C_H=F_event,F_local,F_global 和风格特征 C_S=F_style。

$$ L_{HS-MAD} = \mathbb{E}*{z_0, t, \epsilon, C_H, C_S} [|\epsilon - \epsilon*\theta(z_t, t, C_H, C_S)|_2^2] $$

##### 2.5.2 解耦无分类器指导 (Decoupled CFG) (创新点)

为了独立控制结构遵循度和风格遵循度，我们引入解耦 CFG 策略。

**训练阶段**：我们独立地随机丢弃这两种条件。以概率 p_H 丢弃 C_H（替换为 ∅_H），以概率 p_S 丢弃 C_S（替换为 ∅_S）。这使得模型能够学习所有四种条件组合。

**推理阶段**：我们使用加性 CFG（Additive CFG）公式进行外插，分别控制结构引导强度 w_H 和风格引导强度 w_S：

$$ \begin{aligned} \epsilon_{final} = \epsilon_{\theta}(z_t, \emptyset, \emptyset) &+ w_{H} \cdot (\epsilon_{\theta}(z_t, C_H, \emptyset) - \epsilon_{\theta}(z_t, \emptyset, \emptyset)) \ &+ w_{S} \cdot (\epsilon_{\theta}(z_t, \emptyset, C_S) - \epsilon_{\theta}(z_t, \emptyset, \emptyset)) \end{aligned} $$

这种机制允许用户精确调整生成结果的侧重点，例如，要求严格遵循乐谱（高 w_H），同时探索不同的音色（调整 w_S）。

### 3. 算法细节与伪代码

本节提供 MRCI U-Net 核心解码器块的详细伪代码，展示如何集成 MRCI、跳跃连接调制和风格注入。

**算法 2：MRCI U-Net 解码器块（带跳跃连接调制）**

Python

```
def MRCI_DecoderBlock(Z_up, Z_skip, F_l, t_emb, F_style, gamma_l):
    """
    MRCI U-Net 解码器块。
    Args:
        Z_up: 上一层上采样后的特征图。
        Z_skip: 来自编码器路径的跳跃连接特征图。
        F_l: 当前层级的符号特征 (F_event 或 F_local)。
        t_emb: 时间步嵌入。
        F_style: 全局风格嵌入。
        gamma_l: 跳跃连接调制的可学习门控参数。
    Returns:
        Z_out: 处理后的特征图。
    """
    # 确保时间维度对齐 (由于 HSE 的同步化设计，这应该总是成立)
    assert Z_skip.shape[1] == F_l.shape[1]

    # 1. 跳跃连接调制 (Skip Connection Modulation) (创新点)
    # 使用 TCA 调制 Z_skip，并使用门控参数 gamma_l 控制强度
    Modulation = TemporalCrossAttention(Query=Z_skip, KeyValue=F_l)
    Z_skip_modulated = Z_skip + gamma_l * Modulation

    # 2. 特征融合
    Z = Concatenate(Z_up, Z_skip_modulated)

    # 3. 标准 U-Net 操作 (例如，ResNet/Transformer 块)
    Z = StandardUNetBlock(Z, t_emb)

    # 4. 风格注入 (Style Injection)
    # 使用 FiLM 或 AdaLN 注入全局风格信息 F_style
    Z = ApplyStyle(Z, F_style) # 例如 FiLM(Z, F_style)

    # 5. 结构注入 (Structural Injection)
    # 使用 TCA 再次注入结构信息 F_l，强化结构约束
    Z = Z + TemporalCrossAttention(Query=Z, KeyValue=F_l)

    return Z
```

### 4. 可行性分析与高级技术

#### 4.1 关键技术挑战与解决方案

1. **精确时间同步**：HSE 输出与 U-Net 特征图的对齐是实现 MRCI 的关键。
    - **解决方案**：通过 SRM 实现精确的预同步。仔细设计 VAE、U-Net 和 HSE 的下采样因子，确保其严格匹配。在实现中加入维度断言检查。
2. **音频 VAE 性能瓶颈**：LDM 的性能受限于 VAE 的重建质量，特别是瞬态和相位的保留。
    - **解决方案**：采用最先进的神经音频编解码器，如 EnCodec 或 Descript Audio Codec (DAC)，它们具有高保真度和良好的潜在空间特性。
3. **HSE 层级特征解耦**：如何确保 HSE 提取的特征确实捕捉到了不同层次的音乐信息？
    - **解决方案 [创新点]**：引入辅助任务（Auxiliary Tasks）来引导 HSE 的训练。例如，训练 F_local 预测局部和弦标签（交叉熵损失），训练 F_global 预测全局速度（回归损失）。这些辅助损失与主 LDM 损失联合优化，促进层级解耦。

#### 4.2 可行性论证

HS-MAD 建立在成熟的 LDM 和 Conformer 框架之上，具有高度的可行性。MAESTRO [Hawthorne et al., 2019] 和 Slakh2100 [Manilow et al., 2019] 等高质量对齐数据集提供了必要的数据支持。其核心思想（层级对齐）具有强大的理论支撑，将复杂的生成任务分解为在不同尺度上更容易管理的子任务。

### 5. 实验设计与验证

实验的核心目标是证明 HS-MAD 在音频质量和结构一致性上均优于现有方法。

#### 5.1 数据集

- **MAESTRO**：用于钢琴音乐，验证精确时序控制能力和表现力。
- **Slakh2100**：用于多乐器音乐，验证模型在复杂编曲场景下的泛化能力。

#### 5.2 评估指标

1. **音频保真度 (Fidelity)**：

    - **Fréchet Audio Distance (FAD)** [Kilgour et al., 2019]：评估音色真实感。
    - **主观听觉测试 (MOS)**：评估表现力和自然度。

2. 结构一致性 (Structural Adherence) [核心指标]：

    使用先进的自动音乐转录（AMT）模型（如 MT3）将生成音频转录回 MIDI，并与输入 MIDI 比较。

    - **音符 F1 分数 (Onset/Offset/Pitch)**：衡量音符事件的精确度（采用严格的 50ms 容差）。
    - **时序对齐误差 (Temporal Alignment Error, TAE)**：衡量平均时序漂移（MAE）。
    - **力度相关性 (Velocity Correlation)**：评估动态还原能力。

3. **风格遵循度 (Style Adherence)**：

    - **CLAP 分数**：计算生成音频与文本风格提示之间的语义相似度。

#### 5.3 关键实验

1. **SOTA 性能对比**：
    - **基线**：(a) 全局条件 LDM（仅将符号信息注入瓶颈层）；(b) 扁平条件 LDM（仅注入高分辨率层）；(c) 自回归模型（如 MusicGen）。
    - **预期**：HS-MAD 在结构一致性上显著优于所有基线，同时保持 SOTA 级的 FAD。
2. **消融实验 (Ablation Studies)**：
    - **分层注入的影响**：移除 F_event（预期时序模糊）、F_local 或 F_global（预期结构漂移），验证 MRCI 的有效性。
    - **跳跃连接调制**：移除该机制，验证其对瞬态渲染和 Onset F1 的影响。
    - **解耦 CFG**：对比 Decoupled CFG 与标准 CFG 在控制灵活性和音频质量上的差异。
    - **HSE 架构与辅助任务**：对比 Conformer 与 Transformer，以及有无辅助任务的性能。
3. **解耦控制与风格迁移**：
    - 固定 MIDI 输入，改变风格提示。评估结构保持度（Note F1）和风格遵循度（CLAP Score）。分析不同 w_H 和 w_S 设置下的生成结果。

### 6. 结论

本文提出了 HS-MAD，一个创新的层级符号对齐扩散模型。通过显式地利用音乐层级结构与 U-Net 多分辨率特性之间的同构性，HS-MAD 解决了高保真音频合成与精确结构控制之间的核心矛盾。我们引入了基于 Conformer 的分层符号编码器（HSE）、多分辨率条件注入（MRCI）、创新的跳跃连接调制机制以及解耦无分类器指导（Decoupled CFG）策略。这些设计使得 HS-MAD 能够在生成的每一个抽象层次都受到精确的结构约束，为 AI 音乐合成和创作提供了一个强大而灵活的新范式。