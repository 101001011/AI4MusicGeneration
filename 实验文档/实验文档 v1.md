# AI 音乐生成项目实验设计与代码实现规约

## 1. 基础架构与项目脚手架

本节旨在为 AI 音乐生成研究项目奠定坚实的基础。一个精心设计的项目结构并非个人偏好，而是确保研究可复现性、可扩展性与可维护性的先决条件。通过明确分离数据、源码、配置与实验产出，我们能够构建一个逻辑清晰、易于协作的开发环境。

### 1.1. 目录与文件层级结构

项目将采纳业界主流研究项目的标准化结构。该结构通过逻辑分组，将数据处理、模型核心、实验脚本和配置文件等不同功能的模块解耦，从而显著降低项目的认知负荷与维护成本。

```
music-generation-project/
├── configs/                  # 配置文件目录
│   ├── main_config.yaml      # 主配置文件，实验入口
│   └── model/                # 模型相关配置
│       ├── music_transformer_base.yaml
│       └── music_transformer_large.yaml
├── data/                     # 数据集目录
│   ├── raw/                  # 原始数据集 (例如，MAESTRO MIDI 文件)
│   └── processed/            # 预处理后的数据 (例如,.pkl 或.pt 格式的 token 序列)
├── notebooks/                # Jupyter Notebooks，用于数据探索和实验分析
│   └── 01_data_exploration.ipynb
├── outputs/                  # 所有实验产出的存放目录
│   └── YYYY-MM-DD/           # 按日期组织的实验
│       └── HH-MM-SS/         # 按时间组织的具体运行实例
│           ├── checkpoints/  # 模型权重文件
│           │   └── best_model.pt
│           ├── logs/         # 日志文件，包括 TensorBoard 日志
│           │   └── tensorboard_logs/
│           └── generated_music/ # 生成的音乐样本
│               └── sample_01.mid
├── scripts/                  # 可执行脚本目录
│   ├── preprocess.py         # 数据预处理脚本
│   ├── train.py              # 模型训练脚本
│   ├── evaluate.py           # 模型评估脚本
│   └── generate.py           # 音乐生成脚本
├── src/                      # 核心源代码目录
│   ├── __init__.py
│   ├── data/                 # 数据处理模块
│   │   ├── __init__.py
│   │   ├── dataset.py        # Dataset 类实现
│   │   └── tokenizer.py      # 音乐事件 Tokenizer 实现
│   ├── model/                # 模型定义模块
│   │   ├── __init__.py
│   │   ├── model.py          # 主模型架构
│   │   ├── layers.py         # 自定义层 (如 Attention)
│   │   └── embeddings.py     # 词嵌入与位置编码
│   └── engine/               # 训练与评估引擎
│       ├── __init__.py
│       ├── trainer.py        # 训练器类
│       └── evaluator.py      # 评估器类
├──.gitignore                # Git 忽略文件配置
├── README.md                 # 项目说明文档
└── requirements.txt          # Python 依赖包列表
```

此文件结构的深层设计逻辑借鉴了软件工程中的“关注点分离”原则，其效用远超简单的文件整理。它为研究工作流引入了一种类似模型-视图-控制器 (MVC) 的模式：`src/` 目录包含了项目的核心业务逻辑（模型），`scripts/` 目录充当了调用核心逻辑以完成特定任务的控制器，而 `outputs/` 目录则存储了实验结果（视图）。这种架构模式从根本上解决了研究代码中常见的“面条式代码”问题，即所有逻辑混杂在一个或几个大文件中，导致代码难以阅读、调试和扩展。通过在项目初期就强制实施这种模块化分离，我们确保了每个组件（如数据加载、模型结构、训练循环）都是自包含且可独立测试的单元。这种设计带来的一个重要衍生优势是代码的高度可复用性：例如，`src/engine/trainer.py` 中定义的 `Trainer` 类可以无缝地用于训练一个全新的模型架构，而 `src/data/dataset.py` 中定义的 `MusicDataset` 也可以被一个新的实验脚本调用，从而极大地加速了后续的研究迭代周期。

### 1.2. 配置管理系统

在科研项目中，将实验参数（如学习率、模型层数、批次大小等）硬编码在代码中是导致实验无法复现的主要原因之一。为了根除此问题，我们将采用基于 `OmegaConf` 和 `Hydra` 的配置管理系统，将所有可变参数外部化到 YAML 文件中。这种方法不仅使配置清晰可读，更重要的是，它允许我们通过修改配置文件或命令行参数来启动新的实验，而无需触碰任何源代码。

#### 1.2.1. 主配置文件 (`main_config.yaml`)

此文件是所有实验的入口点，定义了全局参数（如路径、实验名称），并负责组合其他更具体的配置文件（如模型配置）。

```YAML
# configs/main_config.yaml

# 默认配置组合，此处默认加载 base 版本的模型配置
defaults:
  - model: music_transformer_base

# 项目与运行名称
project_name: "AI_Music_Generation_Paper"
run_name: "experiment_001_baseline" # 可通过命令行覆盖

# 数据相关配置
data:
  raw_path: "data/raw/maestro-v3.0.0"
  processed_path: "data/processed/maestro_tokenized.pkl"
  sequence_length: 2048
  batch_size: 16

# 训练相关配置
training:
  epochs: 100
  learning_rate: 3e-4
  optimizer: "AdamW"
  scheduler: "CosineAnnealingLR"
  grad_clip_norm: 1.0
  log_interval: 100      # 每 100 个 step 记录一次日志
  eval_interval: 5000    # 每 5000 个 step 进行一次验证
```

#### 1.2.2. 模型配置文件 (`model/music_transformer_base.yaml`)

每个模型变体都应有其独立的配置文件，详细定义其架构参数。

```YAML
# configs/model/music_transformer_base.yaml

model_name: "MusicTransformer"
n_layers: 6
n_heads: 8
d_model: 512
d_ff: 2048
dropout: 0.1
max_seq_len: 2048
vocab_size: 512 # 该值应在数据预处理后确定并更新
```

选择 `Hydra` 作为配置管理工具是一项具有长远战略意义的决策。它不仅仅是 `argparse` 的一个简单替代品。`Hydra` 的核心优势在于其强大的配置组合能力和命令行多任务运行功能。例如，研究者若想系统地探索不同学习率和模型尺寸对性能的影响，传统方法需要手动修改代码、运行脚本、记录结果，这一过程繁琐且极易出错。而使用 `Hydra`，可以通过一条命令启动所有组合的实验，例如：`python train.py --multirun model=base,large training.learning_rate=1e-4,3e-4`。`Hydra` 会自动为每一次运行创建一个独立的、以配置参数命名的输出目录（如 `outputs/YYYY-MM-DD/HH-MM-SS/model=large,training.learning_rate=1e-4`），并将所有日志、模型和生成结果隔离存放。这种从配置工具到实验效率的直接转化，将研究过程从手工作坊式的尝试转变为系统化、自动化的科学探索，极大地提升了研究生产力。



### 1.3. 依赖包管理 (`requirements.txt`)

为了确保实验环境的一致性和可复现性，所有项目依赖的第三方 Python 包及其精确版本号都必须在 `requirements.txt` 文件中明确列出。这保证了任何研究者在任何机器上都能通过简单的 `pip install -r requirements.txt` 命令搭建起完全相同的运行环境。

```
# 核心机器学习/深度学习框架
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2

# 数据处理与音乐相关库
mido==1.2.10        # 用于解析 MIDI 文件
numpy==1.24.3
pandas==2.0.3       # 用于处理元数据

# 实验管理与工具
omegaconf==2.3.0    # 灵活的配置管理库
hydra-core==1.3.2   # 用于组合配置和管理运行实例
tqdm==4.65.0        # 用于显示进度条
tensorboard==2.13.0 # 用于日志记录和可视化

# 代码质量工具
black==23.3.0
isort==5.12.0
flake8==6.0.0
```

------

## 2. 数据处理与加载流水线 (`src/data/`)

数据是任何机器学习模型的基石，遵循“垃圾进，垃圾出”的基本原则。本节将设计一个健壮、高效且可复现的数据处理流水线，其核心任务是将原始的、连续多维的音乐数据（MIDI 格式）转换为模型能够理解和学习的离散化符号序列。

### 2.1. 音乐事件编码器 (`tokenizer.py`)

`tokenizer.py` 模块是数据表示的核心，其质量直接决定了模型学习的上限。它负责将复杂的音乐概念（如音高、时长、力度）翻译成一个统一的、离散的整数序列（tokens），并能将模型生成的整数序列反向解码为可播放的音乐。

- **类: `MusicTokenizer`**
    - **职责**:
        1. **定义词汇表**: 建立一个从音乐事件到整数 ID 的完整、确定性的映射。
        2. **编码**: 实现将 MIDI 文件转换为 token 整数序列的核心逻辑。
        3. **解码**: 实现将 token 整数序列转换回 MIDI 文件的核心逻辑，用于音乐生成。
    - **接口规范**:
        - `__init__(self, vocab_file: str = None)`: 初始化编码器。如果提供了 `vocab_file`，则加载已有的词汇表；否则，在首次处理数据时创建新的词汇表。
        - `midi_to_tokens(self, midi_path: str) -> List[int]`: 输入一个 MIDI 文件的路径，输出一个整数列表，即 token 序列。
        - `tokens_to_midi(self, tokens: List[int], output_path: str)`: 输入一个 token 序列和目标输出路径，生成并保存一个 MIDI 文件。
        - `vocab_size(self) -> int`: 返回词汇表的大小。

为了确保数据表示的绝对清晰和可复现性，必须以表格形式明确定义音乐事件的编码方案。许多音乐生成领域的论文在描述其数据表示时往往含糊其辞（例如，仅提及“我们使用了一种基于事件的表示方法”），这种模糊性使得其他研究者无法精确复现其工作。通过下表，我们消除了所有歧义，为论文的科学严谨性提供了坚实的基础。

#### 表 2.1: 音乐事件 Tokenization 方案

| 事件类型     | 值域              | Token ID 范围 (示例) | 描述                                                         |
| ------------ | ----------------- | -------------------- | ------------------------------------------------------------ |
| `NOTE_ON`    | 0-127 (MIDI 音高) | 0-127                | 代表一个音符的开始。其值对应 MIDI 音高。                     |
| `NOTE_OFF`   | 0-127 (MIDI 音高) | 128-255              | 代表一个音符的结束。其值对应 MIDI 音高。                     |
| `TIME_SHIFT` | 1-100 (时间步)    | 256-355              | 将音乐时间向前推进 N 个离散步长。例如，1 步长可定义为 10 毫秒。 |
| `VELOCITY`   | 0-31 (量化力度)   | 356-387              | 为后续的 `NOTE_ON` 事件设置音符力度。原始 MIDI 力度 (0-127) 被量化为 32 个等级。 |
| `BOS`        | N/A               | 388                  | `Beginning of Sequence`，序列开始标记。                      |
| `EOS`        | N/A               | 389                  | `End of Sequence`，序列结束标记。                            |
| `PAD`        | N/A               | 390                  | `Padding`，用于填充序列以达到固定长度的标记。                |

这张表格的价值在于，它将研究的核心假设之一——数据表示——从一段描述性的文字转变为一个精确的、可验证的数学规范。任何审稿人或后续研究者都可以依据此表，准确无误地理解 MIDI 文件是如何被转换成模型输入的，这是实现可验证科学研究的第一步，也是最关键的一步。

### 2.2. 数据集类 (`dataset.py`)

该类负责将预处理好的数据高效地组织并提供给训练循环。它将继承 PyTorch 的 `Dataset` 类，并实现数据加载、切分和缓存的核心逻辑。

- **类: `MusicDataset(torch.utils.data.Dataset)`**
    - **职责**:
        1. **数据发现与加载**: 扫描指定目录，找到所有 MIDI 文件。
        2. **预处理与缓存**: 在首次运行时，调用 `MusicTokenizer` 将所有 MIDI 文件转换为 token 序列，并将这些长序列合并。然后，将这个巨大的 token 序列保存到一个二进制文件（如 `processed_path` 指定的 `.pkl` 文件）中。在后续运行时，直接加载这个缓存文件，从而避免了每次都重复进行耗时的 MIDI 解析和 tokenization。
        3. **序列切分**: 将完整的 token 序列切分成多个固定长度（由配置中的 `sequence_length` 定义）的训练样本。
    - **接口规范**:
        - `__init__(self, midi_files: List[str], tokenizer: MusicTokenizer, config: DictConfig)`: 构造函数接收 MIDI 文件列表、一个 `MusicTokenizer` 实例和数据部分的配置。
        - `__len__(self) -> int`: 返回数据集中训练样本的总数（即切分后的序列数量）。
        - `__getitem__(self, idx: int) -> Dict`: 根据索引 `idx` 获取一个训练样本。该样本是一个字典，包含 `{'input_ids':..., 'labels':...}`。对于自回归模型，`input_ids` 是长度为 `L` 的序列，而 `labels` 则是 `input_ids` 向左平移一位的结果，用于计算下一个 token 的预测损失。

### 2.3. 数据整理器 (Data Collator)

数据整理器是一个在 `DataLoader` 中使用的函数，负责将从 `Dataset` 中取出的多个单独样本组合成一个批次 (batch)。对于我们这种已经将数据切分为固定长度序列的情况，整理器相对简单，主要任务是将样本列表转换为一个批次张量。

- **函数: `default_data_collator` (可定义在 `train.py` 或一个工具文件中)**
    - **职责**: 接收一个由 `MusicDataset` 的 `__getitem__` 方法返回的字典样本组成的列表，并将它们堆叠成一个单一的字典，其中每个键对应的值都是一个批次化的 `torch.Tensor`。
    - **接口规范**: `collate_fn(batch: List) -> Dict`。

------

## 3. 核心模型实现架构 (`src/model/`)

本节将技术文档中描述的理论模型，转化为一系列使用 PyTorch 实现的、模块化的、定义清晰的 Python 类。设计的核心原则是代码结构应与论文中的数学公式和模型框图直接对应，以增强代码的可读性和可维护性。

### 3.1. 嵌入层 (`embeddings.py`)

该模块负责将输入的离散 token ID 转换为高维度的连续向量表示，并叠加上位置信息，为后续的 Transformer 层提供输入。

- **类: `MusicEventEmbeddings`**
    - **职责**:
        1. **Token 嵌入**: 维护一个标准的 `torch.nn.Embedding` 层，作为 token ID 到向量的查找表。
        2. **位置嵌入**: 维护一个位置编码层。这可以是一个可学习的绝对位置嵌入 (`torch.nn.Embedding`)，也可以是原始 Transformer 论文中提出的固定的正弦/余弦位置编码。
        3. **组合**: 将 token 嵌入和位置嵌入相加，并应用 Dropout。
    - **接口规范**:
        - `__init__(self, config: DictConfig)`: 根据配置中的 `vocab_size`, `d_model`, `max_seq_len` 等参数初始化嵌入层。
        - `forward(self, input_ids: torch.Tensor) -> torch.Tensor`: 输入 token ID 张量（形状为 `[batch_size, seq_len]`），输出最终的嵌入向量（形状为 `[batch_size, seq_len, d_model]`）。

### 3.2. 自定义注意力/Transformer 层 (`layers.py`)

这是模型核心创新点的实现之处。如果论文提出了新的注意力机制（例如，Music Transformer 中使用的相对位置编码），其全部逻辑都应被封装在此模块的一个独立的 `nn.Module` 中。

- **类: `TransformerEncoderLayer` (或自定义的变体名称)**
    - **职责**:
        1. **多头自注意力**: 实现多头自注意力机制。如果是自定义的机制，所有相关计算（如相对位置编码的集成）都应在此类内部完成。
        2. **前馈网络**: 实现位置无关的前馈网络 (Position-wise Feed-Forward Network)，通常由两个线性层和一个激活函数构成。
        3. **残差连接与层归一化**: 按照标准 Transformer 架构，在自注意力和前馈网络之后分别应用 Dropout、残差连接和层归一化 (`LayerNorm`)。
    - **接口规范**:
        - `__init__(self, config: DictConfig)`: 根据配置中的 `d_model`, `n_heads`, `d_ff`, `dropout` 等参数初始化所有子层。
        - `forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor`: 输入上一层的输出张量和注意力掩码，经过一个完整的 Transformer 编码层处理后，输出同形状的张量。

### 3.3. 主模型 (`model.py`)

该类是模型的总装配车间，它将嵌入层、多个 Transformer 层以及最终的输出层组合成一个完整的、端到端的神经网络。

- **类: `MusicTransformer` (或模型的自定义名称)**
    - **职责**:
        1. **架构搭建**: 实例化 `MusicEventEmbeddings` 层，并根据配置中的 `n_layers` 参数，堆叠多个 `TransformerEncoderLayer` 实例。
        2. **输出头**: 在 Transformer 层的最顶端添加一个最终的层归一化和一个线性层，用于将 `d_model` 维度的输出向量投影回 `vocab_size` 维度的 logits 空间。
        3. **前向传播**: 定义完整的 `forward` 方法。此方法的一个关键步骤是创建因果注意力掩码 (causal attention mask)，以确保在自回归任务中，模型在预测当前 token 时无法“看到”未来的 tokens。
        4. **生成接口**: 实现 `generate` 方法，封装自回归生成的逻辑，包括处理缓存 (KV cache) 以提高长序列生成的效率。
    - **接口规范**:
        - `__init__(self, config: DictConfig)`: 根据模型配置构建完整的模型架构。
        - `forward(self, input_ids: torch.Tensor, labels: torch.Tensor = None) -> Dict`: 模型的统一入口点。当 `labels` 参数被提供时（训练或评估阶段），方法会计算并返回交叉熵损失。当 `labels` 为 `None` 时（推理阶段），方法只返回 logits。输出被封装在一个字典中（例如 `{'loss':..., 'logits':...}`），以提高代码的清晰度和可扩展性。
        - `generate(self, prompt_ids: torch.Tensor, max_length: int, **kwargs) -> torch.Tensor`: 自回归生成方法，接收一个初始的 prompt token 序列，并生成指定长度的后续序列。

将模型代码拆分为 `embeddings.py`, `layers.py`, 和 `model.py` 的设计，体现了软件工程中“组合优于继承”的核心思想。相较于将所有代码塞入一个庞大的单体类，我们构建了多个小而专、功能单一且易于测试的组件，然后像搭积木一样将它们“组合”成最终的模型。这种架构的优越性在研究迭代中尤为突出。假设研究者希望测试一种新的注意力机制，在一个单体模型中，这将意味着对一个庞大而复杂的类进行“心脏手术”，风险高且容易引入新错误。而在我们的模块化设计中，研究者只需在 `layers.py` 中实现一个新的注意力模块类，并确保其接口与旧的一致。然后，在 `model.py` 中，只需修改一行代码（甚至可以通过 YAML 配置来控制），即可将旧的注意力层替换为新的。这种架构选择直接赋能了对模型核心组件的快速、低风险迭代，这正是高效科学研究的精髓所在。

此外，`forward` 方法的 `(..., labels: torch.Tensor = None)` 签名和字典式输出，是借鉴了 Hugging Face Transformers 等业界领先库的最佳实践。这种设计创建了一个统一的接口，无缝支持训练和推理两种模式。当 `labels` 存在时，模型知道自己处于训练或评估模式，并自动计算损失；当 `labels` 为 `None` 时，模型则知道处于推理模式，仅返回预测的 logits。这种设计上的优雅，不仅简化了上层 `Trainer` 的逻辑，也减少了因维护两套独立（训练/推理）代码路径而可能引入的潜在错误，对项目的长期稳健性至关重要。

------

## 4. 实验引擎：训练与评估 (`src/engine/`)

本节定义了用于运行实验的可复用组件。通过将训练和评估循环抽象成专门的类，我们将“模型是什么”（定义在 `src/model/`）与“如何训练模型”（定义在 `src/engine/`）这两个关注点彻底分离。这种解耦是编写清晰、可维护的科研代码的关键。

### 4.1. 训练器 (`trainer.py`)

`Trainer` 类封装了整个训练和验证流程，负责处理优化、梯度更新、学习率调度、模型保存和日志记录等所有工程细节。

- **类: `Trainer`**
    - **职责**:
        1. **主循环管理**: 控制整个训练过程，包括多个 epoch 的迭代。
        2. **训练步骤执行**: 在每个训练步骤中，执行模型的正向传播、损失计算、反向传播和梯度裁剪。
        3. **优化器与调度器**: 调用优化器的 `step()` 方法更新模型参数，并根据设定的策略调用学习率调度器的 `step()` 方法。
        4. **周期性验证**: 按照配置的 `eval_interval`，定期在验证集上运行评估，并记录验证损失、准确率等指标。
        5. **模型检查点**: 保存训练过程中的模型权重。通常会保存性能最佳的模型（基于验证集指标）和最新的模型，以备训练中断后可以恢复。
        6. **度量记录**: 将训练和验证过程中的关键指标（如损失、困惑度、学习率）实时写入 TensorBoard，以便进行可视化监控。
    - **接口规范**:
        - `__init__(self, model, optimizer, train_loader, val_loader, scheduler, config)`: 接收模型、优化器、训练数据加载器、验证数据加载器、学习率调度器和训练配置作为初始化参数。
        - `train(self)`: 启动并管理整个训练流程。
        - `_train_epoch(self)`: 用于执行单个 epoch 训练的私有方法。
        - `_validate_epoch(self)`: 用于执行一次完整验证的私有方法。
        - `_save_checkpoint(self, is_best: bool)`: 用于保存模型状态的私有方法。

`Trainer` 类的设计是一种强大的抽象，它将模型本身与复杂的训练基础设施解耦。这实际上是将软件工程中的“策略模式”应用于深度学习研究。如果没有 `Trainer`，`train.py` 脚本将不可避免地演变成一个冗长、过程化的代码集合，其中混杂着数据循环、优化器调用、日志记录和模型保存等各种逻辑。当研究者希望引入梯度累积、混合精度训练（AMP）或分布式训练（DDP）等高级功能时，就必须直接修改这个已经非常复杂的脚本，这极易引入错误。而通过 `Trainer` 类，这些高级功能可以作为其内部逻辑被添加进去，甚至可以通过配置文件中的一个标志位来开启或关闭。这样，`train.py` 脚本始终保持为一个简洁的高层协调者，其任务仅仅是准备好所有组件（模型、数据、优化器）并将它们交给 `Trainer`。这种分离关注点的设计，为项目的可维护性和未来扩展性带来了巨大的长期收益，让研究者可以更专注于模型本身的创新，而将训练的“工程”部分交由一个健壮、可复用的组件来处理。

### 4.2. 评估器 (`evaluator.py`)

`Evaluator` 类专用于在独立的测试集上对一个已经训练好的模型进行最终的、严格的性能评估。

- **类: `Evaluator`**
    - **职责**:
        1. **加载模型**: 从指定的检查点文件（checkpoint）加载训练好的模型权重。
        2. **评估循环**: 在 `torch.no_grad()` 上下文中遍历测试数据集，以关闭梯度计算，节省内存和计算资源。
        3. **指标计算**: 计算并汇总最终的性能指标，如交叉熵损失、困惑度 (Perplexity)、预测准确率等。
        4. **领域特定指标 (可选)**: 计算更高级的、与音乐领域相关的客观指标，例如音高分布、节奏多样性等，以提供更全面的模型性能画像。
    - **接口规范**:
        - `__init__(self, model, test_loader, config)`: 接收要评估的模型、测试数据加载器和相关配置。
        - `evaluate(self) -> Dict`: 运行完整的评估流程，并返回一个包含所有最终指标的字典。

------

## 5. 可执行脚本与推理流程 (`scripts/`)

`scripts/` 目录下的脚本是用户与项目交互的直接入口。它们被设计为轻量级的包装器，其主要职责是使用 `Hydra` 解析配置，然后实例化 `src/` 目录中定义的核心类，并调用其方法来完成具体任务。

### 5.1. 训练脚本 (`train.py`)

- **目的**: 启动一次完整的模型训练和验证任务。
- **核心逻辑**:
    1. 使用 `@hydra.main` 装饰器，解析 `configs/main_config.yaml` 和所有来自命令行的参数覆盖。
    2. 初始化 `MusicTokenizer`。
    3. 根据配置，为训练集和验证集分别创建 `MusicDataset` 实例和 `DataLoader`。
    4. 初始化 `MusicTransformer` 模型。
    5. 根据配置，初始化优化器（如 `AdamW`）和学习率调度器（如 `CosineAnnealingLR`）。
    6. 将上述所有组件实例化一个 `Trainer` 对象。
    7. 调用 `trainer.train()` 方法，启动训练。

### 5.2. 评估脚本 (`evaluate.py`)

- **目的**: 在测试集上评估一个训练完成的模型检查点。
- **核心逻辑**:
    1. 解析配置，确定要使用的模型架构和测试数据。
    2. 接收一个指向模型权重文件 (`.pt`) 的命令行参数。
    3. 初始化模型，并加载指定的权重。
    4. 初始化测试集的 `DataLoader`。
    5. 实例化 `Evaluator`。
    6. 调用 `evaluator.evaluate()` 方法，并将返回的指标字典打印到控制台或保存到文件中。

### 5.3. 生成脚本 (`generate.py`)

- **目的**: 使用训练好的模型进行创造性的音乐生成。
- **核心逻辑**:
    1. 加载一个训练好的模型检查点。
    2. 加载与模型匹配的 `MusicTokenizer`，用于处理输入的 prompt 和解码模型的输出。
    3. 接收一个音乐片段作为 prompt（可以是一个短 MIDI 文件或一个预设的 token 序列）。
    4. 调用模型的 `generate()` 方法。此方法内部应实现多种解码策略，并通过参数进行控制。
    5. **解码/采样策略实现**:
        - **贪心搜索 (Greedy Search)**: 在每一步都选择概率最高的 token。这种方法最简单，但容易产生重复和缺乏变化的输出。
        - **温度缩放 (Temperature Scaling)**: 在应用 softmax 之前，用一个温度系数 `T` 来调整 logits。当 T>1 时，概率分布变得更平坦，增加了生成的多样性和随机性；当 T<1 时，分布变得更尖锐，趋向于贪心搜索。数学上，新的 logits 为 logits′=logits/T。
        - **Top-k 采样**: 在每一步，将词汇表限制为概率最高的 `k` 个 token，然后在这 `k` 个 token 中根据它们的概率进行采样。这避免了从概率极低的“长尾”词汇中采样。
        - **核心采样 (Nucleus Sampling / Top-p)**: 在每一步，从按概率降序排列的词汇表中，选择一个最小的 token 集合，使得这些 token 的累积概率超过一个阈值 `p`（例如 0.95）。然后，模型仅从这个“核心”集合中进行采样。这种方法比 Top-k 更具适应性，当模型对下一个 token 非常确定时，核心集可能很小；当不确定时，核心集会变大。
    6. 使用 `tokenizer.tokens_to_midi()` 方法，将模型生成的 token 序列转换回可播放的 MIDI 文件，并保存。

解码策略的选择并非一个可选的附加功能，它对生成模型的最终输出质量起着决定性的作用。一个在困惑度（Perplexity）等客观指标上表现优异的模型，如果使用简单的贪心解码，仍然可能生成单调、乏味、不断重复的音乐。这是解码算法的局限，而非模型本身能力的不足。模型学习到的是一个关于下一个 token 的复杂概率分布，贪心搜索仅仅利用了这个分布的峰值信息，而忽略了其他所有可能性。通过实现像核心采样（Top-p）这样的概率采样方法，我们允许模型探索那些概率稍低但仍然合理且可能更有趣的音乐延续。这直接将一个强大的统计模型转化为具有美学价值和创造潜力的艺术工具，弥合了统计性能与艺术表现之间的鸿沟。因此，在 `generate.py` 中提供并实现这些高级采样选项，对于全面展示和评估模型的真实能力至关重要。

------

## 6. 代码质量与文档规范

本节旨在建立一套严格的代码质量标准，确保项目不仅功能完备，而且具备专业性、可读性和长期可维护性。这些标准是高质量科研软件的非协商性要求。

### 6.1. 编码风格 (PEP 8)

所有 Python 代码必须严格遵守 PEP 8 风格指南，以确保代码风格的统一性。

### 6.2. 文档化 (文档字符串与类型提示)

全面的文档是代码可理解性的基石。

- **文档字符串 (Docstrings)**: 每个模块、类和函数都必须包含一个符合 Google 风格的文档字符串。文档字符串应清晰地描述其功能、参数、返回值和可能引发的异常。
- **类型提示 (Type Hinting)**: 所有函数签名（参数和返回值）以及类的属性都必须包含明确的类型提示（使用 `from typing import...`）。类型提示对于静态代码分析、自动补全以及 AI 编程助手（如 Codex）理解代码意图至关重要。

**一个符合规范的函数示例**:

```Python
from typing import List
import torch

def create_causal_mask(seq_len: int) -> torch.Tensor:
    """为序列创建因果注意力掩码 (causal attention mask)。

    该掩码确保注意力头只能关注序列中当前位置之前的位置，
    这对于自回归语言模型是至关重要的。

    Args:
        seq_len (int): 序列的长度。

    Returns:
        torch.Tensor: 一个形状为 [seq_len, seq_len] 的布尔张量，
                      其中 True 值表示该位置被掩码 (mask)。
    """
    # torch.triu 创建一个上三角矩阵，diagonal=1 表示不包括主对角线
    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()
    return mask
```

严格的文档字符串与类型提示相结合，会产生一种强大的协同效应，即创建出一个“自文档化”的代码库。这种代码库对于新加入的合作者（包括几个月后的你自己）来说，学习曲线会大大降低。更重要的是，它极大地增强了 AI 编程助手的能力。当一个函数缺乏类型提示时（如 `def process(data)`），AI 助手无法确切知道 `data` 是列表、张量还是自定义对象，因此其提供的代码补全和建议很可能是基于猜测的，容易出错。而有了明确的类型提示（如 `def process(data: torch.Tensor)`），输入的类型变得毫无歧义。AI 助手便能提供高度准确和相关的代码建议，甚至能提前发现类型不匹配的潜在错误。这形成了一种良性循环：高质量、类型明确的人类代码，赋能了更高质量的 AI 辅助编程，从而整体上加速了整个研究与开发周期。强制执行这一标准，是对未来生产力的一项明智投资。

### 6.3. 注释理念

注释的目的是解释代码背后的“为什么”，而不是复述代码正在“做什么”。如果代码写得足够清晰，其“做什么”应该是自明的。注释应该用来提供额外的上下文，例如：解释某个复杂算法的选择原因、某个特定实现与技术论文中公式的对应关系，或者某个看似奇怪的设计决策背后的考量。

- 所有注释必须使用清晰、专业的中文撰写。

**一个富有洞察力的注释示例**:

```Python
# 我们在这里使用相对位置编码，而不是原始 Transformer 中的绝对正弦编码。
# 根据 Music Transformer (Huang et al., 2018) 的发现，相对位置对于
# 捕捉音乐中的重复模式和结构（如旋律和节奏的模进）至关重要，
# 因为它关注的是音符之间的“距离”而非其在序列中的“绝对位置”。
relative_attention_output = self.attention(query, key, value, pos_embedding)
```

这种注释不仅解释了代码，还将其与相关的学术文献联系起来，为读者提供了深刻的理解。